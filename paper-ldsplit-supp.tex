%% LyX 1.3 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[english, 12pt]{article}
\usepackage{times}
%\usepackage{algorithm2e}
\usepackage{url}
\usepackage{bbm}
\usepackage[T1]{fontenc}
\usepackage[latin1]{inputenc}
\usepackage{geometry}
\geometry{verbose,letterpaper,tmargin=2cm,bmargin=2cm,lmargin=1.5cm,rmargin=1.5cm}
\usepackage{rotating}
\usepackage{color}
\usepackage{graphicx}
\usepackage{amsmath, amsthm, amssymb}
\usepackage{setspace}
\usepackage{lineno}
\usepackage{hyperref}
\usepackage{bbm}
\usepackage{makecell}
\usepackage{placeins}
\usepackage{subcaption}

%\renewcommand{\arraystretch}{1.8}

%\linenumbers
%\doublespacing
\onehalfspacing
%\usepackage[authoryear]{natbib}
\usepackage{natbib} \bibpunct{(}{)}{;}{author-year}{}{,}

%Pour les rajouts
\usepackage{color}
\definecolor{trustcolor}{rgb}{0,0,1}

\usepackage{dsfont}
\usepackage[warn]{textcomp}
\usepackage{adjustbox}
\usepackage{multirow}
\usepackage{subcaption}
\usepackage{graphicx}
\graphicspath{{figures/}}
\DeclareMathOperator*{\argmin}{\arg\!\min}

\let\tabbeg\tabular
\let\tabend\endtabular
\renewenvironment{tabular}{\begin{adjustbox}{max width=0.95\textwidth}\tabbeg}{\tabend\end{adjustbox}}

\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
%% Bold symbol macro for standard LaTeX users
%\newcommand{\boldsymbol}[1]{\mbox{\boldmath $#1$}}

%% Because html converters don't know tabularnewline
\providecommand{\tabularnewline}{\\}
\renewcommand*{\arraystretch}{1.2}

\usepackage{babel}
\makeatother


\begin{document}

\renewcommand{\thefigure}{S\arabic{figure}}
\setcounter{figure}{0}
\renewcommand{\thetable}{S\arabic{table}}
\setcounter{table}{0}
\renewcommand{\theequation}{S\arabic{equation}}
\setcounter{equation}{0}

\section*{Supplementary Materials}

\vspace{3em}

\subsection*{Parameters of \texttt{snp\_ldsplit}}

Function \texttt{snp\_ldsplit} has five parameters:
\begin{itemize}
	\item \texttt{corr}: A sparse correlation matrix, usually the output of \texttt{snp\_cor}.
	\item \texttt{thr\_r2}: Threshold under which squared correlations are ignored. This is useful to avoid counting noise, which should give clearer patterns of costs vs.\ number of blocks. It is therefore possible to have a splitting cost of 0 (a threshold of 5\% is used in this paper). If this parameter is used, then \texttt{corr} can be computed using the same parameter in \texttt{snp\_cor} (to increase the sparsity of the resulting matrix).
	\item \texttt{min\_size}: Minimum number of variants in each block. This is used not to have a disproportionate number of small blocks.
	\item \texttt{max\_size}: Maximum number of variants in each block. This is used not have blocks that are too large, e.g.\ to limit computational and memory requirements of applications that would use these blocks. For some long-range LD regions, it may be needed to allow for large blocks.
	\item \texttt{max\_K}: Maximum number of blocks to consider. All optimal solutions for $K$ from 1 to \texttt{max\_K} will be returned. Some of these $K$ might not have any corresponding solution due to the limitations in size of the blocks. For example, splitting 10,000 variants in blocks with at least 500 and at most 2000 variants implies that there are at least 5 and at most 20 blocks. Then, the choice of K depends on the application, but a simple solution is to choose the largest K for which the cost is lower than some threshold (see e.g.\ figure \ref{fig:costLDSC}).
	
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\FloatBarrier
\clearpage

\subsection*{Procedure to compute optimal costs}

We use the 1000 Genomes (1000G) data in the `.bed' PLINK format provided in \cite{prive2020efficient}, and composed of 2490 individuals and 1,664,852 variants.
In turn, for individuals in each of the five super populations from the 1000G data, we compute the correlation between variants with $\text{MAF} > 0.05$ using function \texttt{snp\_cor} from R package bigsnpr \cite[]{prive2017efficient}, assuming that correlations between variants more than 3 cM away are 0 \cite[]{prive2020ldpred2}.
Then, optimal splits are computed using function \texttt{snp\_ldsplit} introduced in this paper,
setting parameters \texttt{thr\_r2 = 0.05}, \texttt{min\_size = 500}, and \texttt{max\_size = 10000}.
These costs are compared with the costs provided by ldetect \cite[]{berisa2016approximately} for the European and African populations only since they are not provided for the other three super-populations.
Results are presented in figures \ref{fig:costEUR}-\ref{fig:costAMR}. 
We see that splitting costs are very high for the admixed Americans group, showing that it is impossible to split LD in independent blocks in an admixed population.
This is also the case, to a lesser extent, for the African (AFR) group which includes African Americans (ASW) and African Caribbeans (ACB) who may be admixed with e.g.\ European ancestry.
When excluding 5\% of AFR individuals based on principal component analysis, splitting costs are reduced (Figure \ref{fig:costAFR2}).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{figure}[p]
\centerline{\includegraphics[width=0.95\textwidth]{cost_split_EUR}}
\caption{Optimal costs of splitting chromosomes (each panel) in a specified number of blocks (including 500 variants at minimum and 10,000 at maximum) for the European (\textbf{EUR}) super-population in the 1000 Genomes data.
The cost is defined as the sum of squared correlations $r^2$ between variants from different blocks, restricting to all $r^2 > 0.05$.
In red is the cost from the split from ldetect, accessed from \url{https://bitbucket.org/nygcresearch/ldetect-data/src/master/EUR/}.}
\label{fig:costEUR}
\end{figure}


\begin{figure}[p]
\centerline{\includegraphics[width=0.95\textwidth]{cost_split_EAS}}
\caption{Optimal costs of splitting chromosomes (each panel) in a specified number of blocks (including 500 variants at minimum and 10,000 at maximum) for the East Asian (\textbf{EAS}) super-population in the 1000 Genomes data.
The cost is defined as the sum of squared correlations $r^2$ between variants from different blocks, restricting to all $r^2 > 0.05$.}
\label{fig:costEAS}
\end{figure}


\begin{figure}[p]
\centerline{\includegraphics[width=0.95\textwidth]{cost_split_SAS}}
\caption{Optimal costs of splitting chromosomes (each panel) in a specified number of blocks (including 500 variants at minimum and 10,000 at maximum) for the South Asian (\textbf{SAS}) super-population in the 1000 Genomes data.
The cost is defined as the sum of squared correlations $r^2$ between variants from different blocks, restricting to all $r^2 > 0.05$.}
\label{fig:costSAS}
\end{figure}


\begin{figure}[p]
\centerline{\includegraphics[width=0.95\textwidth]{cost_split_AFR}}
\caption{Optimal costs of splitting chromosomes (each panel) in a specified number of blocks (including 500 variants at minimum and 10,000 at maximum) for the African (\textbf{AFR}) super-population in the 1000 Genomes data.
The cost is defined as the sum of squared correlations $r^2$ between variants from different blocks, restricting to all $r^2 > 0.05$.
In red is the cost from the split from ldetect, accessed from \url{https://bitbucket.org/nygcresearch/ldetect-data/src/master/AFR/}.
Here, for the same number of blocks, the cost using ldetect can be smaller than the one with our optimal splitting since we have an additional restriction that blocks should contain at least 500 variants.}
\label{fig:costAFR}
\end{figure}


\begin{figure}[p]
\centerline{\includegraphics[width=0.95\textwidth]{cost_split_AMR}}
\caption{Optimal costs of splitting chromosomes (each panel) in a specified number of blocks (including 500 variants at minimum and 10,000 at maximum) for the Admixed American (\textbf{AMR}) super-population in the 1000 Genomes data.
The cost is defined as the sum of squared correlations $r^2$ between variants from different blocks, restricting to all $r^2 > 0.05$.}
\label{fig:costAMR}
\end{figure}

\begin{figure}[p]
	\centerline{\includegraphics[width=0.95\textwidth]{cost_split_AFR2}}
	\caption{Same as figure \ref{fig:costAFR}, but after excluding 5\% of AFR individuals based on PCA.}
	\label{fig:costAFR2}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\FloatBarrier
\clearpage

\subsection*{Comparison with recombination rates}

\vspace*{3em}

\begin{figure}[h]
	\centerline{\includegraphics[width=0.9\textwidth]{compare_recomb_chr22.pdf}}
	\caption{Recombination rates for chromosome 22 in the CEU population, as provided in \cite{spence2019inference}. Blue dotted lines correspond to boundaries of 22 blocks obtained using \texttt{snp\_ldsplit}, while red dotted lines correspond to the ones from \texttt{ldetect}.}
	\label{fig:bounds-chr22}
\end{figure}

\begin{figure}[h]
	\centerline{\includegraphics[width=0.95\textwidth]{compare_recomb_chr1.pdf}}
	\caption{Recombination rates for chromosome 1 in the CEU population, as provided in \cite{spence2019inference}. Blue dotted lines correspond to boundaries of 133 blocks obtained using \texttt{snp\_ldsplit}, while red dotted lines correspond to the ones from \texttt{ldetect}.}
	\label{fig:bounds-chr1}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\FloatBarrier
\clearpage

\subsection*{Application to LD score regression}

LD score regression is a method to estimate confounding and SNP heritability from summary statistics \cite[]{bulik2015ld}. By default, it uses the delete-a-group jackknife to compute standard errors associated with these two estimates by splitting the genome evenly into 200 blocks of contiguous variants.
These blocks are not always independent, which is breaking one of the assumption of the jackknife. 
Here we aim at investigating the impact of using different blocks to compute standard errors in LD score regression.
We use the function \texttt{snp\_ldsplit} introduced in this paper with the LD reference of 1,054,330 HapMap3 variants provided in \cite{prive2020ldpred2}, and with parameters \texttt{thr\_r2 = 0.05}, \texttt{min\_size = 3000}, and \texttt{max\_size = 10000}. Here, we set \texttt{min\_size = 3000} not to have group sizes varying too much. For each chromosome, we choose the maximum $K$ for which the optimal cost is zero, or very small in the case of chromosome 6 (Figure \ref{fig:costLDSC}).
This results in a total of 242 nearly-independent blocks. We also define another set of 243 blocks by randomly assigning approximately half of the variants of each group to the next group. This manipulation results in having new group boundaries at the middle of the 242 previous ones, introducing LD between neighboring blocks.  

\begin{figure}[p]
	\centerline{\includegraphics[width=0.95\textwidth]{cost_split_ldref.pdf}}
	\caption{Optimal costs of splitting chromosomes (each panel) in a specified number of blocks (including 3000 variants at minimum and 10,000 at maximum) for the European LD reference provided in  \cite{prive2020ldpred2}.
	Red dotted lines highlight the number of blocks chosen for each chromosome.
	The cost is defined as the sum of squared correlations $r^2$ between variants from different blocks, restricting to all $r^2 > 0.05$.}
	\label{fig:costLDSC}
\end{figure}

We use the implementation of LD score regression from R package bigsnpr (function \texttt{snp\_ldsc}, \cite{prive2017efficient}), and modify it to allow for using the jackknife with groups of different sizes \cite[]{busing1999delete}. 
For 245 phenotypes defined elsewhere \cite[]{prive2021high}, we run LD score regression either using the new set of nearly-independent blocks, or with the other set with LD between neighboring blocks.  
Standard errors using nearly-independent blocks tend to be larger than when there is substantial LD between blocks, especially for phenotypes with large associations in the HLA region (a long-range LD region), with e.g.\ standard errors of the SNP heritability estimate of 0.00378 vs.\ 0.00252 for lupus (phecode 695.4), 0.0302 vs.\ 0.0205 for celiac disease (557.1), 0.00420 vs.\ 0.00304 for thyrotoxicosis (242), 0.00313 vs.\ 0.00230 for sicca syndrome (709.2), and 0.00385 vs.\ 0.00294 for hematuria (593).

\begin{figure}[p]
	\centerline{\includegraphics[width=0.95\textwidth]{compare_new_ldsc}}
	\caption{LD score regression results for 245 phenotypes, when using either nearly-independent blocks for jackknifing, or blocks with some LD between neighboring blocks.
	``SE'' means standard error, and are represented using a log scale.}
	\label{fig:newLDSC}
\end{figure}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\FloatBarrier
\clearpage

\bibliographystyle{natbib}
\bibliography{refs}

\end{document}
